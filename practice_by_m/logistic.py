import pandas as pd

admission_data = pd.read_csv("./data/admission.csv")
print(admission_data.shape)

# GPA : í•™ì 
# GRE : ì…í•™ ì‹œí—˜

# í•©ê²©ì„ í•œ ì‚¬ê±´ : Admit    
# Admitì˜ í™•ë¥  ì˜¤ì¦ˆëŠ”? (P(A) / 1 - P(A))

# P(Admit) = í•©ê²© ì¸ì› / ì „ì²´ í•™ìƒ

p_hat = admission_data['admit'].mean()
p_hat / (1 - p_hat)

# p(A) : 0.5ë³´ë‹¤ í° ê²½ìš° - ì˜¤ì¦ˆë¹„: ë¬´í•œëŒ€ì— ê°€ê¹Œì›Œì§ 
# p(A) : 0.5 -> ì˜¤ì¦ˆë¹„ : 1
# p(A) : 0.5ë³´ë‹¤ ì‘ì€ ê²½ìš° -> 0ì— ê°€ê¹Œì›Œì§
# ì˜¤ì¦ˆë¹„ ë²”ìœ„ : 0 ~ ë¬´í•œëŒ€

admission_data['rank'].unique()

grouped_data = admission_data \
           .groupby('rank') \
           .agg(p_admit=('admit', 'mean'))
                
grouped_data['odds'] = grouped_data['p_admit'] / (1 - grouped_data['p_admit'])
print(grouped_data)

# ì˜¤ì¦ˆë¹„ê°€ 3ì´ë©´ P(A)?
# ì˜¤ì¦ˆ(Odds)ë¥¼ ì‚¬ìš©í•œ í™•ë¥  ì—­ì‚° Oddsê°€ ì£¼ì–´ì¡Œì„ ë•Œ, 
# ìœ„ì˜ ê´€ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—­ìœ¼ë¡œ í™•ë¥ ì„ ê³„ì‚°
# ğ‘Ì‚ = ğ‘‚ğ‘‘ğ‘‘ğ‘  / ğ‘‚ğ‘‘ğ‘‘ğ‘  + 1


# admission ë°ì´í„° ì‚°ì ë„ ê·¸ë¦¬ê¸°
# x : gre, y : admit
# admission_data

import seaborn as sns
sns.scatterplot(data = admission_data, x = 'gre', y = 'admit')


#ë¡œì§€ìŠ¤í‹± ë¬¸ì œ í’€ì´ 
import pandas as pd
import numpy as np
import seaborn as sns
import statsmodels.api as sm
from scipy.stats import chi2
from scipy.stats import norm
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ë¬¸ì œ 1.

# ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨ë¸ì„ ì í•©í•˜ê³ , íšŒê·€ í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
# df = pd.read_csv('./data/leukemia_remission.txt', sep='\t')
df_rem = pd.read_csv("../data/leukemia_remission.csv")
df = df_rem.copy()
df

# "admit ~ gre + gpa + rank + gender"
model = sm.formula.logit("REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP", data=df).fit()

print(model.summary())

#ë¬¸ì œ 2
#í•´ë‹¹ ëª¨ë¸ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œê°€ìš”? ê·¸ ì´ìœ ë¥¼ ê²€ì •í†µê³„ëŸ‰ì„ ì‚¬ìš©í•´ì„œ ì„¤ëª…í•˜ì‹œì˜¤.
from scipy.stats import chi2
p_val = 1 - chi2.cdf(-2 * (-17.186 + 10.797), df = 6)
p_val
# LLR p-value:0.04670
# ê²€ì • í†µê³„ëŸ‰ 12.78
# 1 - chi2.cdf(12.78,6) -> LLR p-value
# ìœ ì˜ ìˆ˜ì¤€ 0.05ë³´ë‹¤ ì‘ë‹¤
# ê²°ë¡  : LLR p-value: 0.0467 < ìœ ì˜ìˆ˜ì¤€ 0.05ë³´ë‹¤ ì‘ìœ¼ë‹ˆê¹Œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.

# ë¬¸ì œ 3  
# ë³€ìˆ˜ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œê²Œ 2ê°œì´ë‹¤.
# zì— ëŒ€í•œ p-value ê°’ì´ 0.2 ë³´ë‹¤ ì‘ì€ ë³€ìˆ˜ë“¤
# LI TEMP

# ë¬¸ì œ 4 
# ë‹¤ìŒ í™˜ìì— ëŒ€í•œ ì˜¤ì¦ˆëŠ” ì–¼ë§ˆì¸ê°€ìš”?
# CELL : 65%
# SMEAR : 45%
# INFIL : 55%
# LI : 1.2
# BLAST : 1.1ì„¸í¬/Î¼L
# TEMP : 0.9

log_odds = 64.2581 + 30.8301 * 0.65 + 24.6863 * 0.45 + (-24.9745) * 0.55 + 4.3605 * 1.2 +\
           (-0.0115) * 1.1 + (-100.1734) * 0.9
odds = np.exp(log_odds)
odds

# ë¬¸ì œ 5 
# ìœ„ í™˜ìì˜ í˜ˆì•¡ì—ì„œ ë°±í˜ˆë³‘ ì„¸í¬ê°€ ê´€ì¸¡ë˜ì§€ ì•ŠëŠ” í™•ë¥ ì€ ì–¼ë§ˆì¸ê°€ìš”?
p_h = odds / 1 + odds
#0.076


# ë¬¸ì œ 6 
# 1ì´ë©´ ê´€ì¸¡ ì•ˆë¨ì„ ì˜ë¯¸
# TEMP ë³€ìˆ˜ì˜ ê³„ìˆ˜ëŠ” -100.1734.
# ì²´ì˜¨ì´ 1 ì˜¬ë¼ê°€ë©´ ë¡œê·¸ ì˜¤ì¦ˆëŠ” 100.1734ë§Œí¼ ê°ì†Œ
# ë°±í˜ˆë³‘ ìƒíƒœì— ë„ë‹¬í•  ê°€ëŠ¥ì„±ì´ í¬ê²Œ ì¤„ì–´ë“ ë‹¤


#ë¬¸ì œ 7. CELL ë³€ìˆ˜ì˜ 99% ì˜¤ì¦ˆë¹„ì— ëŒ€í•œ ì‹ ë¢°êµ¬ê°„ì„ êµ¬í•˜ì‹œì˜¤.
# CELL ë³€ìˆ˜ì˜ ê³„ìˆ˜/ í‘œì¤€ ì˜¤ì°¨
cell_coef = 30.8301
cell_std_err = 52.135
# 99% ì‹ ë¢°êµ¬ê°„- Z ê°’
z_99 = norm.ppf(0.995,0,1)
# ì˜¤ì¦ˆë¹„ ì‹ ë¢°êµ¬ê°„
ci_lower = np.exp(cell_coef - z_99 * cell_std_err)
ci_upper = np.exp(cell_coef + z_99 * cell_std_err)

(ci_lower, ci_upper)

#ë¬¸ì œ 8. ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ êµ¬í•œ í›„, 50% ì´ìƒì¸ ê²½ìš° 1ë¡œ ì²˜ë¦¬í•˜ì—¬, í˜¼ë™ í–‰ë ¬ë¥¼ êµ¬í•˜ì‹œì˜¤.
# ì˜ˆì¸¡ í™•ë¥ 
pred_remiss = model.predict(df)
# 50% ì´ìƒì€ 1, ì´í•˜ëŠ” 0
pred_value = (pred_remiss >= 0.5).astype(int)
# pred_value = [1 if x >= 0.5 else 0 for x in pred_remiss] 
actual_value = df['REMISS']  
# í˜¼ë™ í–‰ë ¬ ê³„ì‚°
conf_mat = confusion_matrix(actual_value, pred_value)
p = ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = ('ê´€ì¸¡ê°€ëŠ¥_0', 'ê´€ì¸¡ë¶ˆê°€_1'))
plt.rcParams['font.family'] = 'Malgun Gothic'

print(conf_mat)
p.plot(cmap="Blues") 
plt.clf()


#ë¬¸ì œ 9. í•´ë‹¹ ëª¨ë¸ì˜ AccuracyëŠ” ì–¼ë§ˆì¸ê°€ìš”?
from sklearn.metrics import accuracy_score

(5+15)/(5+3+4+15)  
(5+15)/(5+3+4+15)

accuracy = accuracy_score(actual_value, pred_value)


#ë¬¸ì œ 10. í•´ë‹¹ ëª¨ë¸ì˜ F1 Scoreë¥¼ êµ¬í•˜ì„¸ìš”.
from sklearn.metrics import f1_score

f1 = f1_score(actual_value, pred_value)
f1

precision = 5/(5+3)
recall = 5/(5+4)

2*(precision * recall) / (precision + recall)   # 0.5882352941176471